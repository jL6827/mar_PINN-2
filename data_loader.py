from scaler_manager import ScalerManager
import pandas as pd
import torch
import time

def load_csv_data(file_path, device='cpu'):
    df = pd.read_csv(file_path)

    # æ—¶é—´è½¬æ¢ä¸ºç§’æ•°
    df['time'] = pd.to_datetime(df['time'])
    df['time'] = (df['time'] - df['time'].min()).dt.total_seconds()

    # åˆå§‹åŒ– ScalerManager å¹¶æ‹Ÿåˆ
    scaler_mgr = ScalerManager()
    scaler_mgr.fit(df)

    # å½’ä¸€åŒ–è¾“å…¥ç‰¹å¾
    features_norm = scaler_mgr.transform_all(df)
    inputs = torch.tensor(features_norm, dtype=torch.float32).to(device)

    # æå–ç›®æ ‡é€Ÿåº¦
    targets = df[['uo', 'vo']].values
    targets = torch.tensor(targets, dtype=torch.float32).to(device)

    # æ‹†åˆ†å½’ä¸€åŒ–ç‰¹å¾
    t_norm = inputs[:, 0:1]
    x_norm = inputs[:, 1:2]
    y_norm = inputs[:, 2:3]
    z_norm = inputs[:, 3:4]
    u_true = targets[:, 0:1]
    v_true = targets[:, 1:2]

    return t_norm, x_norm, y_norm, z_norm, u_true, v_true, scaler_mgr, df

""""#def split_dataset_by_time(csv_path, train_ratio=0.8):
    df = pd.read_csv(csv_path)

    # æ—¶é—´è½¬æ¢ä¸ºç§’æ•°ï¼ˆä¸ load_csv_data ä¿æŒä¸€è‡´ï¼‰
    df['time'] = pd.to_datetime(df['time'])
    df['time'] = (df['time'] - df['time'].min()).dt.total_seconds()

    # æŒ‰æ—¶é—´æ’åº
    df_sorted = df.sort_values(by='time').reset_index(drop=True)

    # æŒ‰æ¯”ä¾‹åˆ’åˆ†
    split_index = int(len(df_sorted) * train_ratio)
    train_df = df_sorted.iloc[:split_index].copy()
    test_df = df_sorted.iloc[split_index:].copy()

    print(f"âœ… æ•°æ®åˆ’åˆ†å®Œæˆï¼šè®­ç»ƒé›† {len(train_df)} æ¡ï¼Œæµ‹è¯•é›† {len(test_df)} æ¡")
    print(f"ğŸ“Š æ—¶é—´èŒƒå›´ï¼šè®­ç»ƒé›† time âˆˆ [{train_df['time'].min()}, {train_df['time'].max()}]")
    print(f"ğŸ“Š æ—¶é—´èŒƒå›´ï¼šæµ‹è¯•é›† time âˆˆ [{test_df['time'].min()}, {test_df['time'].max()}]")

    return train_df, test_df
"""
def split_dataset_random(csv_path, train_ratio=0.8, seed=None):
    if seed is None:
        seed = int(time.time()*1000%2**32)


    df = pd.read_csv(csv_path)

    # æ—¶é—´è½¬æ¢ä¸ºç§’æ•°ï¼ˆä¿æŒä¸€è‡´ï¼‰
    df['time'] = pd.to_datetime(df['time'])
    df['time'] = (df['time'] - df['time'].min()).dt.total_seconds()

    # éšæœºæ‰“ä¹±
    df_shuffled = df.sample(frac=1, random_state=seed).reset_index(drop=True)

    # æŒ‰æ¯”ä¾‹åˆ’åˆ†
    split_index = int(len(df_shuffled) * train_ratio)
    train_df = df_shuffled.iloc[:split_index].copy()
    test_df = df_shuffled.iloc[split_index:].copy()

    print(f"âœ… éšæœºåˆ’åˆ†å®Œæˆï¼šè®­ç»ƒé›† {len(train_df)} æ¡ï¼Œæµ‹è¯•é›† {len(test_df)} æ¡")
    return train_df, test_df


def load_csv_data_from_df(df, device='cpu'):
    from scaler_manager import ScalerManager
    import torch

    # æ—¶é—´åˆ—å·²æ˜¯ç§’æ•°ï¼Œæ— éœ€è½¬æ¢
    scaler_mgr = ScalerManager()
    scaler_mgr.fit(df)

    # å½’ä¸€åŒ–è¾“å…¥ç‰¹å¾
    features_norm = scaler_mgr.transform_all(df)
    inputs = torch.tensor(features_norm, dtype=torch.float32).to(device)

    # æå–ç›®æ ‡é€Ÿåº¦
    targets = df[['uo', 'vo']].values
    targets = torch.tensor(targets, dtype=torch.float32).to(device)

    # æ‹†åˆ†å½’ä¸€åŒ–ç‰¹å¾
    t_norm = inputs[:, 0:1]
    x_norm = inputs[:, 1:2]
    y_norm = inputs[:, 2:3]
    z_norm = inputs[:, 3:4]
    u_true = targets[:, 0:1]
    v_true = targets[:, 1:2]

    return t_norm, x_norm, y_norm, z_norm, u_true, v_true, scaler_mgr, df
